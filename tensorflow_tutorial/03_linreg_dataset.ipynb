{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1661.863764550287\n",
      "Epoch 1: 956.3224439573916\n",
      "Epoch 2: 844.6737683409139\n",
      "Epoch 3: 750.7312372197838\n",
      "Epoch 4: 667.659830722252\n",
      "Epoch 5: 594.1417484349327\n",
      "Epoch 6: 529.0787271179651\n",
      "Epoch 7: 471.5003584364135\n",
      "Epoch 8: 420.5458252520938\n",
      "Epoch 9: 375.45531067297253\n",
      "Epoch 10: 335.55436177954664\n",
      "Epoch 11: 300.24627770512666\n",
      "Epoch 12: 269.00374521501146\n",
      "Epoch 13: 241.3595776562824\n",
      "Epoch 14: 216.9003910217238\n",
      "Epoch 15: 195.25972397061292\n",
      "Epoch 16: 176.1137731664483\n",
      "Epoch 17: 159.17551683403158\n",
      "Epoch 18: 144.19069889799545\n",
      "Epoch 19: 130.93503690609023\n",
      "Epoch 20: 119.20935661137888\n",
      "Epoch 21: 108.83793506244884\n",
      "Epoch 22: 99.66458668207358\n",
      "Epoch 23: 91.55171666162971\n",
      "Epoch 24: 84.37658985632197\n",
      "Epoch 25: 78.03213362396008\n",
      "Epoch 26: 72.42178616552172\n",
      "Epoch 27: 67.46132107331957\n",
      "Epoch 28: 63.07563027821873\n",
      "Epoch 29: 59.19871881428714\n",
      "Epoch 30: 55.77163058824279\n",
      "Epoch 31: 52.742706123048954\n",
      "Epoch 32: 50.06563247971506\n",
      "Epoch 33: 47.70006537150391\n",
      "Epoch 34: 45.61017402416389\n",
      "Epoch 35: 43.763794843404014\n",
      "Epoch 36: 42.13259061904698\n",
      "Epoch 37: 40.692217106133775\n",
      "Epoch 38: 39.420219863367905\n",
      "Epoch 39: 38.297008645340895\n",
      "Epoch 40: 37.305592010505066\n",
      "Epoch 41: 36.43066341609841\n",
      "Epoch 42: 35.658454647898296\n",
      "Epoch 43: 34.977248985403655\n",
      "Epoch 44: 34.376551568753236\n",
      "Epoch 45: 33.846705867195695\n",
      "Epoch 46: 33.37967463995998\n",
      "Epoch 47: 32.9680108638946\n",
      "Epoch 48: 32.60548541990942\n",
      "Epoch 49: 32.28618434173986\n",
      "Epoch 50: 32.004961317298495\n",
      "Epoch 51: 31.75752976890163\n",
      "Epoch 52: 31.53978877073019\n",
      "Epoch 53: 31.34836144135732\n",
      "Epoch 54: 31.180118720635072\n",
      "Epoch 55: 31.03225782010038\n",
      "Epoch 56: 30.902463045723714\n",
      "Epoch 57: 30.788599823501748\n",
      "Epoch 58: 30.68872023182676\n",
      "Epoch 59: 30.60122912194102\n",
      "Epoch 60: 30.524589418089263\n",
      "Epoch 61: 30.457532704476954\n",
      "Epoch 62: 30.398964531451316\n",
      "Epoch 63: 30.34777825418737\n",
      "Epoch 64: 30.303121465726413\n",
      "Epoch 65: 30.264247165074092\n",
      "Epoch 66: 30.230395186190357\n",
      "Epoch 67: 30.200965440111528\n",
      "Epoch 68: 30.175501555469697\n",
      "Epoch 69: 30.153343991707324\n",
      "Epoch 70: 30.134226098457216\n",
      "Epoch 71: 30.117758308603477\n",
      "Epoch 72: 30.103543774372174\n",
      "Epoch 73: 30.091394110470336\n",
      "Epoch 74: 30.08093890536509\n",
      "Epoch 75: 30.072084357345624\n",
      "Epoch 76: 30.06452434975899\n",
      "Epoch 77: 30.0581486002297\n",
      "Epoch 78: 30.05278219980139\n",
      "Epoch 79: 30.04828310612785\n",
      "Epoch 80: 30.04458791257593\n",
      "Epoch 81: 30.041549566215345\n",
      "Epoch 82: 30.039046151249817\n",
      "Epoch 83: 30.037039793959796\n",
      "Epoch 84: 30.035464155240486\n",
      "Epoch 85: 30.034287342776263\n",
      "Epoch 86: 30.033386764163456\n",
      "Epoch 87: 30.03276857610855\n",
      "Epoch 88: 30.032388654677273\n",
      "Epoch 89: 30.032152204158926\n",
      "Epoch 90: 30.03209388247043\n",
      "Epoch 91: 30.03219517776896\n",
      "Epoch 92: 30.032402951199575\n",
      "Epoch 93: 30.03264380555698\n",
      "Epoch 94: 30.033044778692265\n",
      "Epoch 95: 30.03343712379727\n",
      "Epoch 96: 30.033913317535955\n",
      "Epoch 97: 30.03442924663878\n",
      "Epoch 98: 30.0349335548615\n",
      "Epoch 99: 30.03552558278714\n",
      "w: -6.070214, b: 84.929512\n",
      "Took: 2.972170 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Solution for simple linear regression example using tf.data\n",
    "Created by Chip Huyen (chiphuyen@cs.stanford.edu)\n",
    "CS20: \"TensorFlow for Deep Learning Research\"\n",
    "cs20.stanford.edu\n",
    "Lecture 03\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils\n",
    "\n",
    "DATA_FILE = 'data/birth_life_2010.txt'\n",
    "\n",
    "# Step 1: read in the data\n",
    "data, n_samples = utils.read_birth_life_data(DATA_FILE)\n",
    "\n",
    "# Step 2: create Dataset and iterator\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "X, Y = iterator.get_next()\n",
    "\n",
    "# Step 3: create weight and bias, initialized to 0\n",
    "w = tf.get_variable('weights', initializer=tf.constant(0.0))\n",
    "b = tf.get_variable('bias', initializer=tf.constant(0.0))\n",
    "\n",
    "# Step 4: build model to predict Y\n",
    "Y_predicted = X * w + b\n",
    "\n",
    "# Step 5: use the square error as the loss function\n",
    "loss = tf.square(Y - Y_predicted, name='loss')\n",
    "# loss = utils.huber_loss(Y, Y_predicted)\n",
    "\n",
    "# Step 6: using gradient descent with learning rate of 0.001 to minimize loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    writer = tf.summary.FileWriter('./graphs/linear_reg', sess.graph)\n",
    "    \n",
    "    # Step 8: train the model for 100 epochs\n",
    "    for i in range(100):\n",
    "        sess.run(iterator.initializer) # initialize the iterator\n",
    "        total_loss = 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l = sess.run([optimizer, loss]) \n",
    "                total_loss += l\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "            \n",
    "        print('Epoch {0}: {1}'.format(i, total_loss/n_samples))\n",
    "\n",
    "    # close the writer when you're done using it\n",
    "    writer.close() \n",
    "    \n",
    "    # Step 9: output the values of w and b\n",
    "    w_out, b_out = sess.run([w, b]) \n",
    "    print('w: %f, b: %f' %(w_out, b_out))\n",
    "print('Took: %f seconds' %(time.time() - start))\n",
    "\n",
    "# plot the results\n",
    "plt.plot(data[:,0], data[:,1], 'bo', label='Real data')\n",
    "plt.plot(data[:,0], data[:,0] * w_out + b_out, 'r', label='Predicted data with squared error')\n",
    "# plt.plot(data[:,0], data[:,0] * (-5.883589) + 85.124306, 'g', label='Predicted data with Huber loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
